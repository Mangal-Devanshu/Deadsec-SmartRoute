# -*- coding: utf-8 -*-
"""Main3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/159tvYZr1QrX7N2MDqUEIhH4HQL0A2hXu
"""

!pip install ipywidgets pandas numpy scikit-learn deap haversine folium hdbscan geopy

import pandas as pd
import numpy as np
from haversine import haversine, haversine_vector
from scipy.spatial import cKDTree
import folium
from heapq import heappush, heappop

class DualGreedyOptimizer:
    def __init__(self, store_loc, vehicles, clusters, range_buffer_percent=0):
        self.store = store_loc  # (lat, lon) tuple of store
        self.vehicles = vehicles  # DataFrame indexed by Vehicle Type
        self.clusters = clusters  # List of clusters
        self.final_trips = []
        self.range_buffer = 1 + (range_buffer_percent / 100)
        self.output_data = []

        # Precompute cluster metadata
        self.cluster_data = self._precompute_cluster_data()
        self.kd_tree = self._build_spatial_index()

    def _precompute_cluster_data(self):
        """Precompute cluster metadata"""
        cluster_data = []
        for cluster in self.clusters:
            points = np.array([[s['Latitude'], s['Longitude']] for s in cluster])
            dist = self._cluster_distance(cluster)
            centroid = np.mean(points, axis=0) if len(points) > 0 else (0, 0)
            cluster_data.append({
                'points': points,
                'size': len(cluster),
                'distance': dist,
                'centroid': centroid
            })
        return cluster_data

    def _build_spatial_index(self):
        """Build spatial index for cluster centroids"""
        centroids = [c['centroid'] for c in self.cluster_data]
        return cKDTree(np.radians(centroids)) if centroids else None

    def _cluster_distance(self, cluster):
        """Calculate cluster distance"""
        points = [self.store] + [(s['Latitude'], s['Longitude']) for s in cluster]
        total = 0
        for i in range(len(points)-1):
            total += haversine(points[i], points[i+1])
        return total + haversine(points[-1], self.store)

    def process_shipments(self):
        """Main processing pipeline"""
        self._process_priority_vehicles('farthest')
        self._process_priority_vehicles('nearest')
        self._process_remaining_with_4w()

    def _process_priority_vehicles(self, strategy):
        """Process priority vehicles with given strategy"""
        for v_type in ['3W', '4W-EV']:
            v_spec = self.vehicles.loc[v_type]
            remaining = int(v_spec['Number'])
            max_cap = v_spec['Shipments_Capacity']
            max_dist = v_spec['Max Trip Radius (in KM)'] * 2 * self.range_buffer

            while remaining > 0 and self.clusters:
                idx = self._select_cluster(strategy, max_dist)
                if idx is None:
                    break

                base = self.clusters[idx]
                merged = self._merge_nearby_clusters(base, v_spec, max_cap)

                if merged and self._validate_trip(merged, v_spec):
                    self._create_trip(merged, v_type)
                    remaining -= 1
                    self._remove_processed_clusters(merged)
                else:
                    self.clusters.pop(idx)
                    self.cluster_data = self._precompute_cluster_data()
                    self.kd_tree = self._build_spatial_index()

    def _select_cluster(self, strategy, max_dist):
        """Select cluster based on strategy"""
        valid = [(i, c['distance']) for i, c in enumerate(self.cluster_data)
                if c['distance'] <= max_dist]
        if not valid:
            return None
        return max(valid, key=lambda x: x[1])[0] if strategy == 'farthest' else min(valid, key=lambda x: x[1])[0]

    def _merge_nearby_clusters(self, base, v_spec, max_cap):
        """Merge nearby clusters with constraints"""
        merged = base.copy()
        time_window = (min(s['start_min'] for s in merged), max(s['start_min'] for s in merged))
        centroid = np.mean([[s['Latitude'], s['Longitude']] for s in merged], axis=0)

        neighbors = self.kd_tree.query_ball_point(
            np.radians(centroid),
            r=np.radians(v_spec['Max Trip Radius (in KM)'] * 2 * self.range_buffer / 111)
        )

        for idx in neighbors:
            candidate = self.clusters[idx]
            if candidate is base:
                continue

            if len(merged) + len(candidate) > max_cap:
                continue

            c_times = [s['start_min'] for s in candidate]
            new_start = min(time_window[0], min(c_times))
            new_end = max(time_window[1], max(c_times))

            if (new_end - new_start) > 240:
                continue

            temp = merged + candidate
            if self._cluster_distance(temp) > v_spec['Max Trip Radius (in KM)'] * 2 * self.range_buffer:
                continue

            merged = temp
            time_window = (new_start, new_end)

        return merged if len(merged) >= v_spec['Shipments_Capacity'] * 0.5 else None

    def _validate_trip(self, cluster, v_spec):
        """Validate trip constraints"""
        return (v_spec['Shipments_Capacity'] * 0.5 <= len(cluster) <= v_spec['Shipments_Capacity'] and
                self._cluster_distance(cluster) <= v_spec['Max Trip Radius (in KM)'] * 2)

    def _create_trip(self, cluster, v_type):
        """Create trip record"""
        v_spec = self.vehicles.loc[v_type]
        dist = self._cluster_distance(cluster)
        time_total = (dist * 5) + (len(cluster) * 10)

        sequenced = sorted(cluster, key=lambda s: (s['start_min'],
                                                   haversine(self.store, (s['Latitude'], s['Longitude']))))

        trip = {
            'TRIP_ID': f"{v_type}_{len(self.final_trips)+1:03d}",
            'Vehicle_Type': v_type,
            'Shipments': len(sequenced),
            'MST_DIST': dist,
            'TRIP_TIME': time_total,
            'CAPACITY_UTI': len(sequenced)/v_spec['Shipments_Capacity'],
            'TIME_UTI': time_total/(v_spec['Max Trip Radius (in KM)'] * 2 * 5),
            'COV_UTI': 1 if dist <= v_spec['Max Trip Radius (in KM)'] * 2 else 0,
            'Cluster': sequenced
        }
        self.final_trips.append(trip)
        self._record_output(trip, sequenced)

    def _remove_processed_clusters(self, processed):
        """Remove processed shipments"""
        processed_ids = set(s['Shipment ID'] for s in processed)
        new_clusters = []
        for cluster in self.clusters:
            new = [s for s in cluster if s['Shipment ID'] not in processed_ids]
            if new:
                new_clusters.append(new)
        self.clusters = new_clusters
        self.cluster_data = self._precompute_cluster_data()
        self.kd_tree = self._build_spatial_index()

    def _process_remaining_with_4w(self):
        """Process remaining shipments with 4W"""
        v_spec = self.vehicles.loc['4W']
        remaining = [s for c in self.clusters for s in c]
        remaining.sort(key=lambda x: x['start_min'])

        while remaining:
            batch = []
            time_window = (float('inf'), -float('inf'))

            for s in remaining:
                new_start = min(time_window[0], s['start_min'])
                new_end = max(time_window[1], s['start_min'] + 120)

                if len(batch) < 25 and (new_end - new_start) <= 240:
                    batch.append(s)
                    time_window = (new_start, new_end)
                else:
                    break

            if batch and self._validate_trip(batch, v_spec):
                self._create_trip(batch, '4W')
                remaining = [s for s in remaining if s not in batch]
            else:
                break

    def _record_output(self, trip, cluster):
        """Generate output records"""
        for idx, s in enumerate(cluster, 1):
            self.output_data.append({
                'TRIP_ID': trip['TRIP_ID'],
                'Shipment_ID': s['Shipment ID'],
                'Latitude': s['Latitude'],
                'Longitude': s['Longitude'],
                'TIME_SLOT': s['Delivery Timeslot'],
                'Shipments': trip['Shipments'],
                'MST_DIST': round(trip['MST_DIST'], 2),
                'TRIP_TIME': round(trip['TRIP_TIME'], 2),
                'Vehicle_Type': trip['Vehicle_Type'],
                'CAPACITY_UTI': round(trip['CAPACITY_UTI'], 2),
                'TIME_UTI': round(trip['TIME_UTI'], 2),
                'COV_UTI': trip['COV_UTI'],
                'Sequence': idx
            })

    def visualize_routes(self):
        """Create interactive map"""
        m = folium.Map(location=self.store, zoom_start=12)
        folium.Marker(self.store,
                    popup='Warehouse',
                    icon=folium.Icon(color='black', icon='warehouse')).add_to(m)

        colors = {'3W': 'red', '4W-EV': 'green', '4W': 'blue'}

        for trip in self.final_trips:
            layer = folium.FeatureGroup(name=f"{trip['TRIP_ID']} ({trip['Vehicle_Type']})",  show=False)
            route_points = [self.store]

            for shipment in trip['Cluster']:
                folium.CircleMarker(
                    location=[shipment['Latitude'], shipment['Longitude']],
                    radius=6,
                    popup=f"Shipment: {shipment['Shipment ID']}",
                    color=colors[trip['Vehicle_Type']],
                    fill=True
                ).add_to(layer)
                route_points.append([shipment['Latitude'], shipment['Longitude']])

            route_points.append(self.store)
            folium.PolyLine(
                locations=route_points,
                color=colors[trip['Vehicle_Type']],
                weight=2,
                popup=f"{trip['TRIP_ID']} - {trip['MST_DIST']:.2f}km"
            ).add_to(layer)

            layer.add_to(m)

        folium.LayerControl().add_to(m)
        m.save('optimized_routes.html')
        return m

    def show_trip_stats(self):
        """Display statistics"""
        stats = {
            'Total Trips': len(self.final_trips),
            '3W Utilization': sum(1 for t in self.final_trips if t['Vehicle_Type'] == '3W'),
            '4W-EV Utilization': sum(1 for t in self.final_trips if t['Vehicle_Type'] == '4W-EV'),
            '4W Utilization': sum(1 for t in self.final_trips if t['Vehicle_Type'] == '4W'),
            'Avg Capacity Utilization': np.mean([t['CAPACITY_UTI'] for t in self.final_trips]) * 100,
            'Avg Distance Utilization': np.mean([t['COV_UTI'] for t in self.final_trips]) * 100,
            'Total Shipments Delivered': sum(t['Shipments'] for t in self.final_trips)
        }

        print("\n" + "="*80)
        print("OPTIMIZATION STATISTICS")
        print("="*80)
        for k, v in stats.items():
            print(f"{k:<30}{v:>15.2f}" + ("%" if "Utilization" in k else ""))
        print("="*80)

    def export_to_excel(self, filename='trip_details.xlsx'):
        """Export to Excel"""
        try:
            df = pd.DataFrame(self.output_data)
            df.sort_values(['TRIP_ID', 'Sequence'], inplace=True)

            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                df.to_excel(writer, index=False, sheet_name='Optimized Trips',
                          columns=['TRIP_ID', 'Shipment_ID', 'Latitude', 'Longitude',
                                   'TIME_SLOT', 'Shipments', 'MST_DIST', 'TRIP_TIME',
                                   'Vehicle_Type', 'CAPACITY_UTI', 'TIME_UTI', 'COV_UTI'])

            print(f"Excel file saved to: {filename}")
        except Exception as e:
            print(f"Export error: {str(e)}")

if __name__ == "__main__":
    from part1 import ClusterOptimizer

    # Load input data
    shipments = pd.read_excel('Data.xlsx', sheet_name='Shipments_Data')
    store_df = pd.read_excel('Data.xlsx', sheet_name='Store Location')
    store_loc = (store_df['Latitute'].iloc[0], store_df['Longitude'].iloc[0])
    vehicles = pd.read_excel('Data.xlsx',
                            sheet_name='Vehicle_Information',
                            index_col='Vehicle Type')

    # Generate initial clusters
    clusterer = ClusterOptimizer(store_loc)
    initial_clusters = clusterer.process_shipments(shipments)

    # Optimize routes
    optimizer = DualGreedyOptimizer(store_loc, vehicles, initial_clusters)
    optimizer.process_shipments()

    # Generate outputs
    optimizer.show_trip_stats()
    optimizer.visualize_routes()
    optimizer.export_to_excel()
    print("Open 'optimized_routes.html' to view interactive map with layered trips")

